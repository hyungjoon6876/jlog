---
layout: post
title: 'Apache kafka 맛보기 (작성중)'
tags: [kafka]
---

## Kafka 
apache kafka는 분산 스트리밍 플랫폼 입니다. apache kafka intro 페이지에는 아래와 같이 소개가 나와있습니다.
스트리밍 플랫폼은 3가지 주요 기능을 갖고 있습니다. 

* 메세지 큐 또는 엔터프라이스 메세징 시스템과 유사하게 record 스트림을 publish 하고 subscribe 합니다.
* fault-tolerant system 안에서 record 스트림을 저장합니다.
* record 스트림 발생했을때 처리합니다.

kafka는 일반적으로 2가지 종류의 어플리케이션에서 사용되어 집니다.
* 시스템 또는 어플리케이션간에 데이터를 안정적으로 얻는 실시간 스트리밍 데이터 파이프라인 구축
* 데이터 스트림을 변환하거나 반응하는 실시간 어플리케이션 구축

소개 페이지에 나와있는 내용들만 보아서는 명확하게 개념이 잡히지는 않았습니다. kafka 의 컨셉에 대해서 이어 나가겠습니다.
* kafka 는  여러 데이터 센터로 확장 될 수 있는 하나이상의 서버에서 cluster 로 동작합니다.
* kafka cluster 는 `topic` 을 저장합니다. `topic`은 record stream을 category에 따라 나눠 놓은 것입니다.
* 각각의 record는 key, value, timestamp 로 구성되어져 있습니다.

kafka 는 4가지 주요 api가 있습니다.

* Producer api : 1가지 또는 그 이상의 `topic`에 record 스트림을 publishing 합니다.
* Consumer api : 1가지 또는 그 이상의 `topic`을 subscribe하고 produced 된 recrod 스트림을 처리 할수 있습니다.
* Stream api
* Connector api

## topics and logs
`topic` 은 publishing 된 record 들의 카테고리 입니다. 또한 하나의 `topic`은 많은 컨슈머를 가질수 있습니다.

topic 의 partition log 구성입니다.

![kafka]({{ site.baseurl }}/assets/img/201808/log_anatomy.png)

각각의 partiton 은 정렬되어 있고 sequence 가 지속적으로 추가되어집니다.


## docker kafka

docker kafka image를 이용해 cluster 구성을 해보겠습니다.
[https://github.com/wurstmeister/kafka-docker](https://github.com/wurstmeister/kafka-docker) 사용한 Dockerfile 입니다.

```bash
$ $KAFKA_HOME/bin/kafka-topics.sh --create --topic jtest --partitions 4 --zookeeper $ZK --replication-factor 2
$ $KAFKA_HOME/bin/kafka-topics.sh --describe --topic topic --zookeeper $ZK 
$ $KAFKA_HOME/bin/kafka-console-producer.sh --topic=jtest --broker-list=`broker-list.sh`
```

```bash
$ $KAFKA_HOME/bin/kafka-console-consumer.sh --topic=topic --bootstrap-server=`broker-list.sh`
```

테스트를 해보았습니다.
![kafka]({{ site.baseurl }}/assets/img/201808/result.gif)


## 출처
* [https://kafka.apache.org/intro](https://kafka.apache.org/intro)
* [https://github.com/wurstmeister/kafka-docker](https://github.com/wurstmeister/kafka-docker)